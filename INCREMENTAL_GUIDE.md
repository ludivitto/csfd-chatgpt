# ğŸš€ InteligentnÃ­ CSFD Scraper - PrÅ¯vodce

## PÅ™ehled

**HlavnÃ­ systÃ©m** pro automatickÃ© pÅ™idÃ¡vÃ¡nÃ­ novÃ½ch filmÅ¯/seriÃ¡lÅ¯ do CSFD datasetu. SystÃ©m pouÅ¾Ã­vÃ¡ inteligentnÃ­ inkrementÃ¡lnÃ­ updates - mÃ­sto scrapovÃ¡nÃ­ vÅ¡eho znovu, detekuje pouze novÃ© poloÅ¾ky a pÅ™idÃ¡vÃ¡ je do datasetu. OptimalizovÃ¡n pro rychlÃ© dennÃ­ kontroly a automatickÃ© pÅ™izpÅ¯sobovÃ¡nÃ­ frekvence podle aktivity.

## ğŸ¯ HlavnÃ­ vÃ½hody

- **Rychlost**: Kontrola novÃ½ch poloÅ¾ek trvÃ¡ 2-5 minut mÃ­sto 3+ hodin
- **Inteligence**: AutomatickÃ© pÅ™izpÅ¯sobovÃ¡nÃ­ frekvence kontrol
- **Efektivita**: Enrichment pouze pro novÃ© poloÅ¾ky
- **Spolehlivost**: AutomatickÃ© zÃ¡lohovÃ¡nÃ­ a error handling

## ğŸ“ Struktura souborÅ¯

```
csfd-chatgpt/
â”œâ”€â”€ incremental_scraper.mjs     # HlavnÃ­ inkrementÃ¡lnÃ­ scraper
â”œâ”€â”€ scrape_csfd.mjs            # PlnÃ½ scraper (pouze manuÃ¡lnÄ›)
â”œâ”€â”€ smart_scheduler.mjs         # InteligentnÃ­ scheduler
â”œâ”€â”€ manage_scraper.mjs          # SprÃ¡vce a monitoring
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ daily.yml              # DennÃ­ workflow (inkrementÃ¡lnÃ­ + manuÃ¡lnÃ­ plnÃ½)
â””â”€â”€ data/
    â”œâ”€â”€ csfd_ratings.json       # HlavnÃ­ dataset
    â”œâ”€â”€ new_items.json          # NovÃ© poloÅ¾ky z poslednÃ­ho bÄ›hu
    â”œâ”€â”€ incremental_state.json  # Stav poslednÃ­ho bÄ›hu
    â””â”€â”€ schedule_config.json    # Konfigurace schedule
```

## ğŸ› ï¸ PouÅ¾itÃ­

### ZÃ¡kladnÃ­ pÅ™Ã­kazy

```bash
# TestovÃ¡nÃ­ inkrementÃ¡lnÃ­ho scraperu
npm run scrape-inc

# SprÃ¡va a testovÃ¡nÃ­
npm run manage status
npm run manage test-inc
npm run manage stats

# SprÃ¡va schedule
npm run schedule --update
```

### DetailnÃ­ pÅ™Ã­kazy

```bash
# ZobrazenÃ­ stavu
node manage_scraper.mjs status

# TestovÃ¡nÃ­
node manage_scraper.mjs test-inc
node manage_scraper.mjs test-full

# Statistiky
node manage_scraper.mjs stats

# ÄŒiÅ¡tÄ›nÃ­
node manage_scraper.mjs cleanup
```

## âš™ï¸ Konfigurace

### InkrementÃ¡lnÃ­ scraper (`incremental_scraper.mjs`)

```javascript
const config = {
  settings: {
    maxPagesToCheck: 5,        // Kolik strÃ¡nek zkontrolovat
    maxNewItems: 50,           // Max novÃ½ch poloÅ¾ek na bÄ›h
    enableEnrichment: true,    // Zda enrichovat novÃ© poloÅ¾ky
    createBackup: true,        // VytvoÅ™it zÃ¡lohu
    verbose: true,             // DetailnÃ­ logovÃ¡nÃ­
  }
};
```

### Smart scheduler

SystÃ©m automaticky upravuje frekvenci podle aktivity:

- **0 novÃ½ch poloÅ¾ek**: KaÅ¾dÃ½ den v 2:00 UTC (3 strÃ¡nky)
- **1-5 novÃ½ch poloÅ¾ek**: KaÅ¾dÃ½ den v 2:00 UTC (5 strÃ¡nek)
- **6-20 novÃ½ch poloÅ¾ek**: 2x dennÄ› v 2:00 a 14:00 UTC (8 strÃ¡nek)
- **20+ novÃ½ch poloÅ¾ek**: KaÅ¾dÃ½ch 6 hodin (10 strÃ¡nek)

## ğŸ”„ Workflow

### 1. InkrementÃ¡lnÃ­ kontrola
```mermaid
graph TD
    A[SpuÅ¡tÄ›nÃ­] --> B[NaÄtenÃ­ existujÃ­cÃ­ch dat]
    B --> C[Kontrola prvnÃ­ch strÃ¡nek]
    C --> D{Nalezeny novÃ© poloÅ¾ky?}
    D -->|Ano| E[Enrichment novÃ½ch poloÅ¾ek]
    D -->|Ne| F[UkonÄenÃ­]
    E --> G[UloÅ¾enÃ­ do hlavnÃ­ho datasetu]
    G --> H[Aktualizace schedule]
    H --> F
```

### 2. Enrichment proces
- **IMDb ID**: AutomatickÃ© vyhledÃ¡nÃ­
- **OriginÃ¡lnÃ­ nÃ¡zev**: Extrakce z CSFD
- **Å½Ã¡nr**: ZÃ­skÃ¡nÃ­ z detailnÃ­ strÃ¡nky
- **ReÅ¾isÃ©r**: Extrakce z creators sekce
- **Popis**: ZkrÃ¡cenÃ½ popis (max 200 znakÅ¯)

## ğŸ“Š Monitoring

### Stav souborÅ¯
- `data/csfd_ratings.json` - HlavnÃ­ dataset
- `data/new_items.json` - NovÃ© poloÅ¾ky z poslednÃ­ho bÄ›hu
- `data/incremental_state.json` - Stav a statistiky
- `data/schedule_config.json` - AktuÃ¡lnÃ­ konfigurace schedule

### GitHub Actions
- **AutomatickÃ© spouÅ¡tÄ›nÃ­**: Podle schedule
- **ManuÃ¡lnÃ­ spuÅ¡tÄ›nÃ­**: S moÅ¾nostÃ­ vÃ½bÄ›ru reÅ¾imu
- **Commit zmÄ›n**: AutomatickÃ© commitovÃ¡nÃ­ novÃ½ch poloÅ¾ek
- **Artifacts**: UloÅ¾enÃ­ debug informacÃ­

## ğŸš¨ Troubleshooting

### ÄŒastÃ© problÃ©my

1. **Å½Ã¡dnÃ© novÃ© poloÅ¾ky nenalezeny**
   ```bash
   node manage_scraper.mjs status
   # Zkontrolujte, zda existuje hlavnÃ­ dataset
   ```

2. **Chyby pÅ™i enrichment**
   ```bash
   node manage_scraper.mjs test-inc
   # Testujte s verbose vÃ½stupem
   ```

3. **ProblÃ©my se schedule**
   ```bash
   node smart_scheduler.mjs --update
   # Aktualizujte schedule konfiguraci
   ```

### Debug reÅ¾im

```bash
# SpuÅ¡tÄ›nÃ­ s detailnÃ­m logovÃ¡nÃ­m
node incremental_scraper.mjs --verbose

# ZobrazenÃ­ poslednÃ­ch novÃ½ch poloÅ¾ek
node manage_scraper.mjs recent

# ÄŒiÅ¡tÄ›nÃ­ doÄasnÃ½ch souborÅ¯
node manage_scraper.mjs cleanup
```

## ğŸ“ˆ VÃ½kon

### PorovnÃ¡nÃ­ s pÅ¯vodnÃ­m systÃ©mem

| Metrika | PÅ¯vodnÃ­ scraper | InkrementÃ¡lnÃ­ |
|---------|----------------|---------------|
| ÄŒas bÄ›hu | 3+ hodiny | 2-5 minut |
| ZatÃ­Å¾enÃ­ | VysokÃ© | NÃ­zkÃ© |
| Frekvence | TÃ½dnÄ› | DennÄ›/ÄastÄ›ji |
| NovÃ© poloÅ¾ky | VÅ¡echny | Pouze novÃ© |

### Optimalizace

- **Cache**: OpakovanÃ© poÅ¾adavky se cachujÃ­
- **AdaptivnÃ­ delays**: PÅ™izpÅ¯sobenÃ­ podle response time
- **Chunked processing**: ZpracovÃ¡nÃ­ po malÃ½ch dÃ¡vkÃ¡ch
- **Error recovery**: AutomatickÃ© opakovÃ¡nÃ­ pÅ™i chybÃ¡ch

## ğŸ”§ RozÅ¡Ã­Å™enÃ­

### PÅ™idÃ¡nÃ­ novÃ½ch polÃ­

1. Upravte `incremental_scraper.mjs` - pÅ™idejte extrakci
2. Aktualizujte `extractBasicDetails` funkci
3. Testujte s `npm run manage test-inc`

### ZmÄ›na schedule logiky

1. Upravte `smart_scheduler.mjs`
2. ZmÄ›Åˆte `config.baseSchedule` hodnoty
3. SpusÅ¥te `npm run schedule --update`

## ğŸ“ PoznÃ¡mky

- SystÃ©m je navrÅ¾en pro stabilnÃ­ provoz
- AutomatickÃ© zÃ¡lohovÃ¡nÃ­ pÅ™ed zmÄ›nami
- KompatibilnÃ­ s existujÃ­cÃ­m workflow
- MoÅ¾nost fallback na plnÃ½ scraper

## ğŸ†˜ Podpora

Pro problÃ©my nebo otÃ¡zky:
1. Zkontrolujte logy: `node manage_scraper.mjs status`
2. Testujte: `node manage_scraper.mjs test-inc`
3. Zkontrolujte GitHub Actions artifacts
4. VytvoÅ™te issue s logy a popisem problÃ©mu
