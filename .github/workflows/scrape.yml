name: Scrape CSFD

on:
  # Weekly schedule (Mon 03:00 UTC). Adjust as needed.
  schedule:
    - cron: "0 3 * * 1"
  # Allow manual runs from the Actions tab.
  workflow_dispatch: {}

jobs:
  scrape:
    runs-on: ubuntu-latest
    permissions:
      contents: write   # required to push changes back to the repo

    steps:
      # 1) Checkout repository
      - name: Checkout
        uses: actions/checkout@v4

      # 2) Setup Node.js
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20

      # 3) Install dependencies and Playwright Chromium
      - name: Install deps (Playwright + Chromium)
        run: |
          npm i
          npx playwright install --with-deps chromium

      # 4) Run the scraper (produces data/csfd_ratings.csv and data/csfd_ratings.json)
      - name: Run scraper
        # run: node scrape_csfd.mjs
        run: node scrape_csfd.mjs --maxPages 1 # for testing

      # 5) Commit only if data has changed
      - name: Commit data if changed
        if: success()
        run: |
          set -e
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add data/csfd_ratings.csv data/csfd_ratings.json || true
          if ! git diff --cached --quiet; then
            git commit -m "Update CSFD dataset [skip ci]"
            git push
          else
            echo "No data changes; skipping commit."
          fi

      # 6) Always upload debug artifacts (screenshots/HTML) if present
      - name: Upload debug artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: debug
          path: |
            debug/**